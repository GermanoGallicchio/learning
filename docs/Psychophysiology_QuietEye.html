<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/quarto-contrib/qrcodejs-v1.0.0/qrcode.js"></script><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <title>Learning resources – psychophysiology_quieteye</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto-0fde88a82f0356838740f155f1088782.css">
  <link rel="stylesheet" href="custom.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section id="hot-topics-in-sport-and-exercise-quiet-eye" class="slide level2 nostretch center">
<h2>Hot Topics in Sport and Exercise: Quiet Eye</h2>
<div class="columns">
<div class="column" style="width:80%;">
Dr Germano Gallicchio <br>
<div style="font-size:0.8em">
<p>Lecturer in Psychophysiology and Cognitive Neuroscience</p>
<p>School of Psychology and Sport Science, Bangor University, UK <br></p>
<p><a href="https://www.bangor.ac.uk/staff/spss/germano-gallicchio-530785/en">profile</a> | <a href="https://scholar.google.com/citations?user=i3h3GbMAAAAJ&amp;hl=en">research</a> | <a href="https://github.com/GermanoGallicchio">software</a> | <a href="https://germanogallicchio.github.io/learning/">learning resources</a> | <a href="https://outlook.office.com/book/SHESStaffTutorialandDropInHours@bangoroffice365.onmicrosoft.com/?login_hint">book meeting</a></p>
</div>
<p><br></p>
<div style="font-size:0.6em">
<p>On a computer press F11 to de/activate full-screen view.</p>
<p>For smartphone and review: Bottom left menu -&gt; Tools -&gt; PDF Export Mode.</p>
<p>For pdf document: use “learning resources” link above.</p>
<p>Last modified: 2026-02-08</p>
</div>
</div><div class="column" style="width:20%;">
<p>QR code to<br>these slides: </p><div id="" class="qrcode"></div>
<script type="text/javascript">
(function() {
  var script = document.currentScript;
  var qrcode = script.previousElementSibling;
  qrcode.qrcode = new QRCode(qrcode, {"colorDark":"#0011bb","colorLight":"#ffffff","height":128,"text":"https://germanogallicchio.github.io/learning/Psychophysiology_QuietEye.html?view=scroll","width":128});
  script.remove();
})();
</script>
    <p></p>
<p><br></p>
<span class="pulse" style="font-weight: bold; color: rgba(255,40,0,0.6);">PIN</span>
<div contenteditable="true" style="
    min-height: 0;
    padding: 0;
    font-size: 2.5em;
    color: rgba(255,40,0,0.6)
">
0000
</div>
</div></div>
<style>
.pulse {
  animation: pulse 2s ease-in-out infinite;
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.3; }
}
</style>
</section>
<section id="objectives" class="title-slide slide level1">
<h1>Objectives</h1>
<p>Being able to:</p>
<ul>
<li class="fragment">describe the Quiet Eye effect</li>
<li class="fragment">explain algorithms to quantify Quiet Eye duration from EOG data</li>
<li class="fragment">critically evaluate studies using EOG to measure the Quiet Eye</li>
<li class="fragment">optional, present methodology and findings to your peers (flipped classroom approach)</li>
</ul>
</section>

<section>
<section id="seminar-structure" class="title-slide slide level1">
<h1>Seminar structure</h1>
<p><strong>Part 1</strong>, Lecturer-driven</p>
<ul>
<li class="fragment">what is the Quiet Eye</li>
<li class="fragment">relation between Quiet Eye and performance</li>
<li class="fragment">how is it typically measured</li>
<li class="fragment">how it can be measured with the EOG</li>
</ul>
<p><strong>Part 2</strong>, Student-driven (flipped classroom)</p>
<ul>
<li class="fragment">Protected time for students to (re)read their chosen paper and then have a small-group discussion of pros/cons/future directions.</li>
</ul>
</section>
<section id="part-1-is-there-an-optimal-oculomotor-pattern-for-better-performance" class="slide level2 center">
<h2>Part 1: Is there an optimal oculomotor pattern for better performance?</h2>

<img data-src="./Psychophysiology_files/gazeGolf.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"></section></section>
<section id="the-quiet-eye-effect" class="title-slide slide level1 scrollable">
<h1>The Quiet Eye effect</h1>
<p>Performance advantage conferred by a <strong>steady ocular fixation</strong> on a critical target of an action.</p>
<div class="columns">
<div class="column">
<iframe width="100%" height="30%" src="https://youtube.com/embed/knfC978EoWc" title="Scientific American Frontiers, Season 12, Episode 06
On the Ball - My Quiet Eye." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<div class="fragment">
<p><strong>Quiet Eye is the time duration wherein:</strong></p>
</div>
<ul>
<li class="fragment">gaze is on a critical visual target of the action (e.g., golf ball)</li>
<li class="fragment">onset before movement initiation</li>
<li class="fragment">offset when gaze deviates from target of a certain quantity</li>
</ul>
</div><div class="column">
<div class="fragment">
<p><strong>Relation between QE and performance</strong></p>
<p>Medium to very large effects reported in meta-analysis (Lebeau et al., 2016).</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="Psychophysiology_QuietEye_files/figure-revealjs/unnamed-chunk-1-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div>
</div></div>

<aside><div>
<div class="fragment">
<p>Lebeau, J. C., Liu, S., Sáenz-Moncaleano, C., Sanduvete-Chaves, S., Chacón-Moscoso, S., Becker, B. J., &amp; Tenenbaum, G. (2016). Quiet eye and performance in sport: A meta-analysis. Journal of Sport and Exercise Psychology, 38(5), 441-457. <a href="https://doi-org.bangor.idm.oclc.org/10.1123/jsep.2015-0123">https://doi-org.bangor.idm.oclc.org/10.1123/jsep.2015-0123</a>.</p>
</div>
</div></aside></section>

<section id="how-is-the-qe-typically-measured" class="title-slide slide level1">
<h1>How is the QE <em>typically</em> measured?</h1>
<p>Through camera-based eye-tracking technology. It requires measuring time during which the critical object lies within 3 deg of visual angles.</p>
<p><span class="fragment">Very tedius, time-consuming, and subjective manual coding procedure.</span></p>

<img data-src="./Psychophysiology_files/gazeQE.png" class="quarto-figure quarto-figure-center r-stretch" style="width:70.0%"></section>

<section id="can-the-eog-be-used-to-measure-the-qe" class="title-slide slide level1">
<h1>Can the <em>EOG</em> be used to measure the QE?</h1>
<div class="fragment">
<p>Yes. But no less challenging. Some advantages: more objective and automatable. Biggest limitation: no spatial information.</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./Psychophysiology_files/eogQE.png" class="quarto-figure quarto-figure-center" style="width:100.0%"></p>
</figure>
</div>
</div>
</section>

<section id="two-approaches-to-quantify-qe-duration" class="title-slide slide level1 scrollable">
<h1>Two approaches to quantify QE duration</h1>
<p><strong><span style="color: blue;">Dispersion-based algorithm</span></strong></p>
<ul>
<li class="fragment">Monitors eye <em>position</em> stability</li>
<li class="fragment">Detects when the eyes remain within a spatial window</li>
<li class="fragment">Analogous to fixation detection in eye-tracking</li>
</ul>
<p><strong><span style="color: orange;">Velocity-based algorithm</span></strong></p>
<ul>
<li class="fragment">Monitors eye movement <em>velocity</em></li>
<li class="fragment">Detects when eye velocity falls below threshold</li>
</ul>

<aside><div>
<p>Both implemented in:</p>
<p>Gallicchio, G. (2023). Quiet-Eye-EOG. <em>Zenodo</em>. <a href="https://doi.org/10.5281/zenodo.8411093">https://doi.org/10.5281/zenodo.8411093</a>.</p>
</div></aside></section>

<section id="commonalities" class="title-slide slide level1 scrollable">
<h1>Commonalities</h1>
<ul>
<li class="fragment">Both algorithms assume that a critical event happens at time 0 (e.g., movement initiation).</li>
<li class="fragment">Both algorithms identify the Quiet Eye <strong>onset</strong> (working backward from time 0) and Quiet Eye <strong>offset</strong> (working forward from time 0).</li>
<li class="fragment">By definition, QE onset must occur <em>before</em> movement initiation (negative time), whereas QE offset must occur <em>at or after</em> movement initiation (zero or positive time).</li>
<li class="fragment">Total QE duration is measured as the time interval from Quiet Eye onset to offset.</li>
<li class="fragment">We don’t know for sure where participants are looking at. Both algorithms make a big assumption: that the eyes are on the target at time 0. This assumption is often not unreasonable, based on literature and empirical evidence.</li>
</ul>

<aside><div>
<div class="fragment">
<p>And more recent evidence suggests it does not matter where exactly the eyes are looking at.</p>
</div>
</div></aside></section>

<section id="dispersion-algorithm-concept" class="title-slide slide level1 nostretch scrollable">
<h1><em>Dispersion</em> algorithm: Concept</h1>
<p><strong><span style="color: blue;">Core principle</span></strong>: The eyes are “quiet” when their <em>position</em> stays <em>within</em> a narrow range. That is, its dispersion does not overcome a set <em>threshold</em>.</p>
<p>More on the threshold later.</p>
<div class="fragment">
<p><strong><span style="color: blue;">Key steps:</span></strong></p>
</div>
<ol type="1">
<li class="fragment">Identify time 0 (e.g., movement initiation)</li>
<li class="fragment">Work backwards from time 0, one point at a time, and compare the EOG value at that point with the EOG value at time 0</li>
</ol>
<ol type="A">
<li class="fragment">If the comparison yields a value that is within threshold: we are still within a “quiet” period, so keep working backwards (repeat step 2).</li>
<li class="fragment">Otherwise, stop: you have found the first time point outside of the Quiet Eye period. The Quiet Eye onset is immediately after that point</li>
</ol>
<ol start="4" type="1">
<li class="fragment">Same procedure for Quiet Eye offset but move forward</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./Psychophysiology_files/eogCalibrated.jpg" style="width:100.0%"></p>
<figcaption>EOG Quiet Eye scoring</figcaption>
</figure>
</div>
</section>

<section id="dispersion-algorithm-the-100-ms-rule-for-temporal-constrain" class="title-slide slide level1">
<h1><em>Dispersion</em> algorithm: the 100 ms rule (for temporal constrain)</h1>
<p>Optional, but often implemented</p>
<p><span class="fragment">The EOG is a noisy signal. A brief boundary violation (e.g., a short spike in the EOG) shouldn’t necessarily end the QE period. Short, transient deviations should be tolerated, and only sustained exits should count as true violations.</span></p>
<p><span class="fragment">Implementation: the EOG signal should exceed the threshold for at least 100 ms.</span></p>
<p><span class="fragment">Why 100 ms? This is a conventional standard from perception science suggesting that a stable fixation cannot be shorter than 100 ms. But some variation exists in the literature (ranging from 60-150 ms depending on the application).</span></p>
</section>

<section id="dispersion-algorithm-median-filter" class="title-slide slide level1">
<h1><em>Dispersion</em> algorithm: median filter</h1>
<p>It is convenient to simplify the EOG signal to get rid of (reduce) short-lived features and retain flat portions and edges in the signal (indicating fixations and saccades).</p>
<p><span class="fragment">The median filter is ideal. A running window is slid along the signal and for each window, the median is computed.</span></p>
<p><span class="fragment">This filter needs one parameters: the length of the running window.</span></p>
<p><span class="fragment">How to choose it? Also no objective answer, and (cross)validation would be useful.</span></p>

<aside><div>
<div class="fragment">
<p>The first validation of median filter parameters was done in Gallicchio, G., Ryu, D., Krishnani, M., Tasker, G. L., Pecunioso, A., &amp; Jackson, R. C. (2024). Temporal and spectral electrooculographic features in a discrete precision task. <em>Psychophysiology, 61</em>(3), <a href="https://doi.org/10.1111/psyp.14461">https://doi.org/10.1111/psyp.14461</a>.</p>
</div>
</div></aside></section>

<section id="velocity-algorithm-concept" class="title-slide slide level1 nostretch scrollable">
<h1><em>Velocity</em> algorithm: Concept</h1>
<p><strong><span style="color: orange;">Core principle</span></strong>: The eyes are “quiet” when they move slowly. That is, when they move at a velocity within a set <em>threshold</em>.</p>
<p>More on the threshold later.</p>
<div class="fragment">
<p><strong><span style="color: orange;">Key steps:</span></strong></p>
</div>
<ol type="1">
<li class="fragment">Compute eye velocity from EOG signal (i.e., rate of change of position over time). For a time series use “differentiation” (computing the “derivative”, aka “rate of change”).</li>
<li class="fragment">Identify time 0 (e.g., movement initiation)</li>
<li class="fragment">Work backwards from time 0, one point at a time, and compare the EOG velocity at that point with the EOG velocity at time 0</li>
</ol>
<ol type="A">
<li class="fragment">If the comparison yields a value that is within threshold: we are still within a “quiet” period, so keep working backwards (repeat step 2).</li>
<li class="fragment">Otherwise, stop: you have found the first time point outside of the Quiet Eye period. The Quiet Eye onset is immediately after that point</li>
</ol>
<ol start="4" type="1">
<li class="fragment">Same procedure for Quiet Eye offset but move forward</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="./Psychophysiology_files/eogCalibrated.jpg" style="width:100.0%"></p>
<figcaption>EOG Quiet Eye scoring</figcaption>
</figure>
</div>
</section>

<section id="velocity-algorithm-smoothing-filter" class="title-slide slide level1">
<h1><em>Velocity</em> algorithm: smoothing filter</h1>
<p>Differentiating a signal tends to amplify high-frequency noise. Therefore, it is important to smooth the signal before computing velocity.</p>
<p><span class="fragment">For a noisy time series use “Savitzky-Golay filter”. A running window is slid along the signal. For each window, a polynomial is fitted to the data points within that window. The polynomial (and not the raw data) is differentiated. The central point of the window is then replaced with the value predicted by the differentiated polynomial.</span></p>
<p><span class="fragment">This filter needs two parameters: the length of the running window and the order of the polynomial.</span></p>
<p><span class="fragment">How to choose them? Also no objective answer, and (cross)validation would be useful.</span></p>

<aside><div>
<div class="fragment">
<p>The first validation of Savitzky-Golay filter parameters was done in Gallicchio, G., Ryu, D., Krishnani, M., Tasker, G. L., Pecunioso, A., &amp; Jackson, R. C. (2024). Temporal and spectral electrooculographic features in a discrete precision task. <em>Psychophysiology, 61</em>(3), <a href="https://doi.org/10.1111/psyp.14461">https://doi.org/10.1111/psyp.14461</a>.</p>
</div>
</div></aside></section>

<section id="threshold" class="title-slide slide level1">
<h1>Threshold</h1>
<p>How to decide within which range eye movements are still considered “quiet eye”?</p>
<p><span class="fragment">Most of the eye-tracking literature uses 3 degrees (dispersion algorithm) or 33 degrees / second (velocity algorithm) as criterion to define fixations.</span></p>
<p><span class="fragment">However, there is no objective answer and the threshold should be (cross)validated on the data at hand.</span></p>

<aside><div>
<div class="fragment">
<p>The first validation of threshold was done in Gallicchio, G., Cooke, A., &amp; Ring, C. (2018). Assessing ocular activity during performance of motor skills using electrooculography. <em>Psychophysiology, 55</em>(7), 1-12. <a href="https://doi.org/10.1111/psyp.13070">https://doi.org/10.1111/psyp.13070</a>.</p>
</div>
</div></aside></section>

<section id="dispersion-vs.-velocity-conceptual-differences" class="title-slide slide level1">
<h1>Dispersion vs.&nbsp;Velocity: Conceptual differences</h1>
<table class="caption-top">
<colgroup>
<col style="width: 14%">
<col style="width: 46%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th><strong><span style="color: blue;">Dispersion algorithm</span></strong></th>
<th><strong><span style="color: orange;">Velocity algorithm</span></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Question</strong></td>
<td>“Are the eyes staying roughly in the same place?”</td>
<td>“Are the eyes moving relatively slowly?”</td>
</tr>
<tr class="even">
<td><strong>What it measures</strong></td>
<td>Changes in EOG position*</td>
<td>Changes in EOG velocity*</td>
</tr>
<tr class="odd">
<td><strong>Advantage</strong></td>
<td>More intuitive, directly relates to visual fixation</td>
<td>Less sensitive to drift and baseline shifts</td>
</tr>
</tbody>
</table>
<p><span class="fragment">Note: * Relative to a set threshold</span></p>
</section>

<section>
<section id="open-questions" class="title-slide slide level1 hidden">
<h1>Open questions</h1>
<p>What to do when there is no Quiet Eye period? Should researchers say that Quiet Eye was zero or that there is no Quiet Eye? Subtle but important repercussions on data analysis.</p>
</section>
<section id="part-2-critical-evaluation-of-studies-using-the-eog-to-measure-the-quiet-eye" class="slide level2">
<h2>Part 2: Critical evaluation of studies using the EOG to measure the Quiet Eye</h2>
<p>Pick one of these two papers:</p>
<ol type="1">
<li class="fragment"><p>Gallicchio, G., Cooke, A., &amp; Ring, C. (2018). Assessing ocular activity during performance of motor skills using electrooculography. <em>Psychophysiology, 55</em>(7), 1-12. <a href="https://doi.org/10.1111/psyp.13070">https://doi.org/10.1111/psyp.13070</a>.</p></li>
<li class="fragment"><p>Gallicchio, G., &amp; Ring, C. (2020). The quiet eye effect: A test of the visual and postural-kinematic hypotheses. <em>Sport, Exercise &amp; Performance Psychology, 9</em>(1), 143-159. <a href="http://dx.doi.org/10.1037/spy0000162">http://dx.doi.org/10.1037/spy0000162</a>.</p></li>
</ol>
<p><span class="fragment">Focus on dis/advantages, opportunities, and limitations. These are already mentioned in the papers–try to find hem. But also think outside the box and try to come up with your own.</span></p>
<p><span class="fragment">Optionally, discuss in groups/with the lecturer.</span></p>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,

        height: 720,

        // Factor of the display size that should remain empty around the content
        margin: 1.0e-2,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>